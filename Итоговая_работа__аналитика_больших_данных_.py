# -*- coding: utf-8 -*-
"""Итоговая работа "Аналитика больших данных".ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M1-oqiUobqW4FA54JvY8EAXm_K3XXsys
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

"""Задание 1"""

# Оценки
df_ratings = pd.read_csv('u.data.csv', sep='\t', header=None)
df_ratings.columns = ['user_id', 'movie_id', 'rating', 'timestamp']
df_ratings.head()

# Фильмы
df_movies = pd.read_csv('u.item.csv', sep='|', header=None, encoding='latin1')
df_movies.columns = ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', 'Children\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']
df_movies.head()

"""Задание 2"""

# Подсчет количества оценок каждого пользователя
user_ratings_count = df_ratings['user_id'].value_counts()

# Находим id пользователя с наибольшим количеством оценок
max_ratings_user_id = user_ratings_count.idxmax()
max_ratings_user_id

"""Задание 3"""

df_ratings_new = df_ratings[df_ratings['user_id'] == max_ratings_user_id]
df_ratings_new.head()

"""Задание 4"""

# Объединяем датафреймы
df_merged = pd.merge(df_ratings_new, df_movies, on='movie_id', how='left')

# Добавляем колонку с годом
df_merged['year'] = df_merged['release_date'].apply(lambda x: x[-4:])

# Удаляем лишние колонки
df_merged = df_merged.drop(columns=['user_id', 'timestamp', 'release_date', 'video_release_date', 'IMDb_URL'])
df_merged.head()

# Общее количество оценок от всех пользователей на фильм и суммарные оценки от всех пользователей
sum_data = df_ratings.groupby('movie_id').sum().reset_index()
count_data = df_ratings.groupby('movie_id').count().reset_index()

# Добавляем столбцы с суммой и количеством оценок
df_merged = pd.merge(df_merged, sum_data[['movie_id', 'rating']], on='movie_id')
df_merged = pd.merge(df_merged, count_data[['movie_id', 'rating']], on='movie_id')
df_merged.rename(columns={'rating_x': 'rating', 'rating_y': 'rating_sum', 'rating': 'rating_count'}, inplace=True)
df_merged.head()

"""Задание 5"""

# Разделяем данные на признаки (X) и целевую переменную (y)
X = df_merged[['year', 'rating_sum', 'rating_count', 'unknown', 'Action', 'Adventure', 'Animation', 'Children\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']]
y = df_merged['rating']

# Разделяем данные на обучающий и тестовый наборы
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Задание 6"""

# Создаем модель линейной регрессии и обучаем её на обучающем наборе
model = LinearRegression()
model.fit(X_train, y_train)

# Делаем предсказания на тестовом наборе
predictions = model.predict(X_test)

"""Задание 7"""

# Оцениваем качество модели
mse = mean_squared_error(y_test, predictions)
mse

"""Установка PySpark"""

!apt-get update

!apt-get install openjdk-8-jdk-headless -qq > /dev/null

!wget -q https://downloads.apache.org/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3-scala2.13.tgz

!tar -xvf spark-3.4.3-bin-hadoop3-scala2.13.tgz

!pip install -q findspark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.4.3-bin-hadoop3-scala2.13"

import findspark
findspark.init()
from pyspark.sql import SparkSession
from pyspark.sql.functions import mean
from pyspark.sql.functions import col, desc

spark = SparkSession.builder.master("local[*]").getOrCreate()

"""Задание 8"""

df_ratings = spark.read.option("delimiter", "\t").csv('u.data.csv', inferSchema=True)
df_ratings.show()

df_movies = spark.read.option("delimiter", "|").csv('u.item.csv', inferSchema=True)
df_movies.show()

"""Задание 9"""

average_ratings_per_movie = df_ratings.groupBy("_c1").avg("_c2")
average_ratings_per_movie.show()

"""Задание 10"""



"""Задание 11"""

# Подсчет количества оценок для каждого фильма
movie_rating_count = df_ratings.groupBy("_c1").count()

# Получение датафрейма с 5-ю самыми популярными фильмами
df_top_movies = movie_rating_count.orderBy(desc("count")).limit(5)
df_top_movies.show()

# Получение датафрейма с 5-ю самыми непопулярными фильмами
df_bottom_movies = movie_rating_count.orderBy("count").limit(5)
df_bottom_movies.show()